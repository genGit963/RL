{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f2a3684-1ede-4652-a937-37bf7227e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d9b3e0-b9b9-4eaf-8785-9af56106920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Blackjack-v1', render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62685b46-2345-4750-a473-6b562575f831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57546661-a842-44bf-90c8-d7755b8b9d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2da004-cd5f-4855-a2b9-545ce8a0ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epi: 1, score:-1.0\n",
      "epi: 2, score:-1.0\n",
      "epi: 3, score:-1.0\n",
      "epi: 4, score:-1.0\n",
      "epi: 5, score:-1.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "    print(\"epi: {}, score:{}\".format(episode, score))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d16789b-0bb6-4115-8cb6-9f52474b26af",
   "metadata": {},
   "source": [
    "# training of agent based on the Monto-Carlo Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bfc90f-e8bc-4b93-9af0-46264fed5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = env.reset()\n",
    "for i in range(3)\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    action= next_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9b29636-f5bd-48f2-b201-b7678967875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episodes_from_limit_stochastic(bj_env):\n",
    "    print(generate_episodes_from_limit_stochastic)\n",
    "    episode = []\n",
    "    state = bj_env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        statep = int(state[0][0])\n",
    "        print(statep)\n",
    "        if statep > 18:\n",
    "            probs = [0.8, 0.2] \n",
    "        else:\n",
    "            probs = [0.2, 0.8]\n",
    "        action = np.random.choice(np.arange(2), p= probs)\n",
    "        next_state, reward, done, truncated, info = bj_env.step(action)\n",
    "        episode.append((state, reward, action))\n",
    "        state = next_state\n",
    "    print(episode)\n",
    "    return episode\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8e1c527-27fd-46f1-a8bf-ac213eea6945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18, 10, 1), {})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d6eab6b-0c4e-4f43-bcc1-a32f201314c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     generate_episodes_from_limit_stochastic(env)\n",
      "Cell \u001b[0;32mIn[61], line 7\u001b[0m, in \u001b[0;36mgenerate_episodes_from_limit_stochastic\u001b[0;34m(bj_env)\u001b[0m\n\u001b[1;32m      4\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m----> 7\u001b[0m     statep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(state[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(statep)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m statep \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m18\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    generate_episodes_from_limit_stochastic(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "744a8ede-4819-4df8-8b47-8d92261be45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>, {})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultdict(lambda: np.zeros(env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dc1b949-8e74-4562-bc27-61cb28d5545a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93d45e92-5012-4c17-990f-cf4fecdcde26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = zip(*[10,10,120,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c4fbe-855a-4e3b-9ab0-9314cb0bd7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a610ef03-cb36-42a1-b248-066d23a84da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_prediction_q(env, n_episodes, generate_episode, gamma = 1.0):\n",
    "    #initiate empty dicts\n",
    "    returns_sum = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "    # loop over the episodes\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        # monitor progress\n",
    "        if i_episode % 1000 == 0:\n",
    "            print(\"Episode: {}\".format(i_episode))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        #generate episodes \n",
    "        episode  = generate_episode(env)\n",
    "\n",
    "        # obtain state, action and reward\n",
    "        states, actions, rewards = zip(*episode)\n",
    "\n",
    "        #discounts \n",
    "        discounts = np.array([gamma**i for i in range(len(rewards)+1)])\n",
    "\n",
    "        # update sum of returns, number of visits and action-value\n",
    "        # function estimates for each state-action pair in the episode\n",
    "        for i, state in enumerate(states):\n",
    "            returns_sum[state][actions[i]] += sum(rewards[i:]*discounts[:-(1+i)])\n",
    "            N[state][actions[i]] += 1.0\n",
    "            Q[state][actions[i]] += returns_sum[state][actions[i]]/N[state][actions[i]]\n",
    "    return Q\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e193390-f65f-40c8-acb2-24674af243b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m episode \u001b[38;5;241m=\u001b[39m generate_episodes_from_limit_stochastic(env)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(episode)\n\u001b[1;32m      4\u001b[0m states, actions, rewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mepisode)\n",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m, in \u001b[0;36mgenerate_episodes_from_limit_stochastic\u001b[0;34m(bj_env)\u001b[0m\n\u001b[1;32m      4\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m18\u001b[39m:\n\u001b[1;32m      8\u001b[0m         probs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.2\u001b[39m] \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "episode = generate_episodes_from_limit_stochastic(env)\n",
    "print(episode)\n",
    "\n",
    "states, actions, rewards = zip(*episode)\n",
    "\n",
    "print(\"States: \", states)\n",
    "print(\"Actions: \", actions)\n",
    "print(\"Rewards: \", rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29aef32a-03a5-4d0c-9490-1fca58f6d426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[(((18, 7, 0), {}), 1.0, 0)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Q \u001b[38;5;241m=\u001b[39m mc_prediction_q(env\u001b[38;5;241m=\u001b[39menv, n_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, generate_episode\u001b[38;5;241m=\u001b[39mgenerate_episodes_from_limit_stochastic)\n",
      "Cell \u001b[0;32mIn[32], line 27\u001b[0m, in \u001b[0;36mmc_prediction_q\u001b[0;34m(env, n_episodes, generate_episode, gamma)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# update sum of returns, number of visits and action-value\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# function estimates for each state-action pair in the episode\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(states):\n\u001b[0;32m---> 27\u001b[0m     returns_sum[state][actions[i]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(rewards[i:]\u001b[38;5;241m*\u001b[39mdiscounts[:\u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mi)])\n\u001b[1;32m     28\u001b[0m     N[state][actions[i]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     29\u001b[0m     Q[state][actions[i]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m returns_sum[state][actions[i]]\u001b[38;5;241m/\u001b[39mN[state][actions[i]]\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "Q = mc_prediction_q(env=env, n_episodes=10000, generate_episode=generate_episodes_from_limit_stochastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d4442-9fd0-4af9-918e-f5554ab48e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
